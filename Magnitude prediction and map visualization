import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
import numpy as np
import folium
from folium.plugins import MarkerCluster
from shapely.geometry import Point
import geopandas as gpd
from sklearn.metrics import mean_absolute_error

# Upload the CSV file
from google.colab import files

uploaded = files.upload()

# Read CSV file with space delimiter
# Assuming the uploaded file is named 'Earthquake_data_processed (1).csv'
df = pd.read_csv("Earthquake_data_processed.csv")

# Continue with the rest of your code
ts = pd.to_datetime(df["Date(YYYY/MM/DD)"] + " " + df["Time(UTC)"])
df = df.drop(["Date(YYYY/MM/DD)", "Time(UTC)"], axis=1)
df.index = ts


# Select relevant columns
X = df[['Latitude(deg)', 'Longitude(deg)', 'Depth(km)', 'No_of_Stations']]
y = df['Magnitude(ergs)']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

from sklearn.linear_model import LinearRegression
# Train the linear regression model
regressor = LinearRegression()
regressor.fit(X_train, y_train)

from sklearn.metrics import r2_score, mean_squared_error

scores= {"Model name": ["Linear regression", "SVM", "Random Forest","Neural Network","XGBoost","Gradient Boosting"], "mse": [], "R^2": [], "mae":[]}

# Predict on the testing set
y_pred = regressor.predict(X_test)

# Compute R^2 and MSE
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
mae_linear = mean_absolute_error(y_test, y_pred)

scores['mse'].append(mse)
scores['R^2'].append(r2)
scores['mae'].append(mae_linear)
print("R^2: {:.2f}, MSE: {:.2f},MAE:{:.2f}".format(r2, mse,mae_linear))


from sklearn.svm import SVR

# Select a subset of the training data
subset_size = 500
X_train_subset = X_train[:subset_size]
y_train_subset = y_train[:subset_size]

# Create an SVM model
svm = SVR(kernel='rbf', C=1e3, gamma=0.1)

# Train the SVM model on the subset of data
svm.fit(X_train_subset, y_train_subset)

# Evaluate the model on the test set
score = svm.score(X_test, y_test)
print("Test score:", score)

# Predict on the testing set
y_pred_svm = svm.predict(X_test)

# Compute R^2 and MSE
r2_svm = r2_score(y_test, y_pred_svm)
mse_svm = mean_squared_error(y_test, y_pred_svm)
mae_svm = mean_absolute_error(y_test, y_pred_svm)

scores['mse'].append(mse_svm)
scores['R^2'].append(r2_svm)
scores['mae'].append(mae_svm)

print("SVM R^2: {:.2f}, MSE: {:.2f},MAE:{:.2f}".format(r2_svm, mse_svm,mae_svm))


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
from sklearn.svm import SVC

style.use('fivethirtyeight')

# create mesh grids
def make_meshgrid(x, y, h =.02):
    x_min, x_max = x.min() - 1, x.max() + 1
    y_min, y_max = y.min() - 1, y.max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))
    return xx, yy

# plot the contours
def plot_contours(ax, clf, xx, yy, **params):
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    out = ax.contourf(xx, yy, Z, **params)
    return out

# color = ['y', 'b', 'g', 'k']

subset_size = 500

# modify the column names based on the dataset
features = df[['Magnitude(ergs)','Latitude(deg)']][:subset_size].values
classes = df['Magnitude_type'][:subset_size].values

# create 3 svm with rbf kernels
svm1 = SVC(kernel ='rbf')
svm2 = SVC(kernel ='rbf')
svm3 = SVC(kernel ='rbf')
svm4 = SVC(kernel ='rbf')

# fit each svm's
svm1.fit(features, (classes=='ML').astype(int))
svm2.fit(features, (classes=='Mx').astype(int))
svm3.fit(features, (classes=='Md').astype(int))

fig, ax = plt.subplots()
X0, X1 = features[:, 0], features[:, 1]
xx, yy = make_meshgrid(X0, X1)

# plot the contours
'''
plot_contours(ax, svm1, xx, yy, cmap = plt.get_cmap('hot'), alpha = 0.8)
plot_contours(ax, svm2, xx, yy, cmap = plt.get_cmap('hot'), alpha = 0.3)
plot_contours(ax, svm3, xx, yy, cmap = plt.get_cmap('hot'), alpha = 0.5)
'''
color = ['y', 'b', 'g', 'k', 'm']



for i in range(subset_size):
    if classes[i] == 'ML':
        plt.scatter(features[i][0], features[i][1], s = 20, c = color[0])
    elif classes[i] == 'Mx':
        plt.scatter(features[i][0], features[i][1], s = 20, c = color[1])
    elif classes[i] == 'Md':
        plt.scatter(features[i][0], features[i][1], s = 20, c = color[2])
    else:
        plt.scatter(features[i][0], features[i][1], s = 20, c = color[4])
plt.show()

print(df.columns)
df['Magnitude_type'].unique()


from sklearn.ensemble import RandomForestRegressor

# Initialize a random forest regressor with 100 trees
rf = RandomForestRegressor(n_estimators=100, random_state=42)

# Fit the regressor to the training data
rf.fit(X_train, y_train)

# Predict the target variable on the test data
y_pred = rf.predict(X_test)

# Evaluate the performance of the model using mean squared error and R^2 score
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
mae_rf = mean_absolute_error(y_test, y_pred)

scores['mse'].append(mse)
scores['R^2'].append(r2)
scores['mae'].append(mae_rf)

print('Mean Squared Error: ', mse)
print('R^2 Score: ', r2)


from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler

# Standardize the input features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)



# Initialize the neural network regressor
mlp = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)

# Fit the regressor to the training data
mlp.fit(X_train_scaled, y_train)

# Predict on the testing set
y_pred_nn = mlp.predict(X_test_scaled)

# Evaluate the performance of the model using mean squared error and R^2 score
mse_nn = mean_squared_error(y_test, y_pred_nn)
r2_nn = r2_score(y_test, y_pred_nn)
mae_nn = mean_absolute_error(y_test, y_pred_nn)

scores['mse'].append(mse_nn)
scores['R^2'].append(r2_nn)
scores['mae'].append(mae_nn)

print("Neural Network R^2: {:.2f}, MSE: {:.2f}, MAE:{:.2f}".format(r2_nn, mse_nn,mae_nn))


from sklearn.ensemble import GradientBoostingRegressor

# Initialize Gradient Boosting regressor
gb = GradientBoostingRegressor(n_estimators=100, random_state=42)

# Fit the regressor to the training data
gb.fit(X_train, y_train)

# Predict on the testing set
y_pred_gb = gb.predict(X_test)

# Evaluate the performance of the model using mean squared error and R^2 score
mse_gb = mean_squared_error(y_test, y_pred_gb)
r2_gb = r2_score(y_test, y_pred_gb)
mae_gb = mean_absolute_error(y_test, y_pred_gb)

scores['mse'].append(mse_gb)
scores['R^2'].append(r2_gb)
scores['mae'].append(mae_gb)

print("Gradient Boosting R^2: {:.2f}, MSE: {:.2f},MAE:{:.2f}".format(r2_gb, mse_gb,mae_gb))


from xgboost import XGBRegressor

# Initialize XGBoost regressor
xgb = XGBRegressor(objective='reg:squarederror', random_state=42)

# Fit the regressor to the training data
xgb.fit(X_train, y_train)

# Predict on the testing set
y_pred_xgb = xgb.predict(X_test)

# Evaluate the performance of the model using mean squared error and R^2 score
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)

scores['mse'].append(mse_xgb)
scores['R^2'].append(r2_xgb)
scores['mae'].append(mae_xgb)

print("XGBoost R^2: {:.2f}, MSE: {:.2f},MAE: {:.2f}".format(r2_xgb, mse_xgb,mae_xgb))



plt.scatter(y_test, y_pred_nn)
plt.xlabel('Actual Magnitude')
plt.ylabel('Predicted Magnitude')
plt.title('Neural Network Regression Results')
plt.show()

# Visualize weights for Neural Network
weights_nn = np.abs(mlp.coefs_[0])  # Consider the absolute value of each weight separately
mean_weights_nn = weights_nn.mean(axis=1)  # Take the mean across neurons in the layer
features_nn = ['Latitude', 'Longitude', 'Depth', 'No_of_Stations']  # Assuming you have the same features

# Ensure mean_weights_nn is a 1D array
mean_weights_nn = mean_weights_nn.ravel()

plt.bar(features_nn, mean_weights_nn)
plt.xlabel('Feature')
plt.ylabel('Mean Weight')
plt.title('Neural Network Feature Importance Plot')
plt.show()


# Residual plot for Neural Network
import seaborn as sns
sns.residplot(x=y_test, y=y_pred_nn, color='orange')
plt.xlabel('Predicted Magnitude')
plt.ylabel('Residual')
plt.title('Neural Network Residual Plot')
plt.show()

# Actual vs. Predicted Line Plot for Neural Network
plt.plot(y_test.index[:20], y_test[:20], color='blue', label='Actual Magnitude')
plt.plot(y_test.index[:20], y_pred_nn[:20], color='orange', label='Predicted Magnitude')
plt.xlabel('Index')
plt.ylabel('Magnitude')
plt.title('Neural Network Actual vs. Predicted Line Plot')
plt.legend()
plt.show()


scores_df = pd.DataFrame(scores)
display(scores_df)

scores_df[scores_df["mse"] == scores_df["mse"].min()]

scores_df[scores_df["R^2"] == scores_df["R^2"].max()]


# Modify this part according to your needs for user input
user_input = [float(input("Enter Latitude: ")),
              float(input("Enter Longitude: ")),
              float(input("Enter Depth: ")),
              float(input("Enter No. of Stations: "))]

# Predict using the linear regression model
# Include 'No_of_Stations' as the fourth feature
new_pred = regressor.predict(np.array(user_input).reshape(1, -1))
print("New Linear Regression predictions:", new_pred)

# Predict using SVM
new_pred_svm = svm.predict(np.array(user_input).reshape(1, -1))
print("New SVM predictions:", new_pred_svm)

# Predict using the neural network model
new_pred_nn = mlp.predict(scaler.transform(np.array(user_input).reshape(1, -1)))
print("New Neural Network predictions:", new_pred_nn)


# Calculate affected area based on magnitude and depth
magnitude = new_pred_nn[0]
depth = user_input[2]


# You can adjust these coefficients based on your needs
magnitude_coefficient = 0.1  # Adjust according to the impact of magnitude on affected area
depth_coefficient = 0.05  # Adjust according to the impact of depth on affected area

buffer_size = magnitude_coefficient * magnitude + depth_coefficient * depth

# Print the calculated affected area
print("Calculated Affected Area:", buffer_size)

# Calculate affected area based on magnitude and depth
affected_area = Point(user_input[1], user_input[0]).buffer(buffer_size)

# Create a GeoDataFrame for visualization with a CRS
gdf = gpd.GeoDataFrame(geometry=[affected_area], crs='EPSG:4326')

# Create a map with markers and affected area
m = folium.Map(location=[df['Latitude(deg)'].mean(), df['Longitude(deg)'].mean()], zoom_start=3)

marker_cluster = MarkerCluster().add_to(m)

# Add markers and affected area for predictions
color = 'red' if new_pred[0] >= 5 else ('orange' if 3 <= new_pred[0] < 5 else 'yellow')

# Add markers for predictions
folium.CircleMarker(
    location=[user_input[0], user_input[1]],
    radius=5,
    color=color,
    fill=True,
    fill_color=color,
    fill_opacity=0.7,
    popup=f"Magnitude: {new_pred[0]}",
).add_to(marker_cluster)

# Add GeoDataFrame with affected area to the map
folium.GeoJson(gdf).add_to(m)

# Show the map
m
